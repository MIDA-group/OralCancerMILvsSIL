{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from pathlib import Path\n",
    "from dataloader import PAPQMNIST_SIL\n",
    "from models import ModelParallelResNet18, Lenet, ModelParallelSqueezeNet\n",
    "from aux_functions import list_files_in_folder, create_save_dir, create_list_of_files_in_given_folder, working_dataset,list_files_oral_cancer3_focused, transformations_dataset_oral_cancer3_focused, load_dataset, postproc, _preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch PAPQMNIST/OC bags Example')\n",
    "parser.add_argument('--epochs', type=int, default=150, metavar='N',\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, metavar='LR',\n",
    "                    help='learning rate (default: 0.0005)') #0.0001\n",
    "parser.add_argument('--reg', type=float, default=10e-6, metavar='R',\n",
    "                    help='weight decay') \n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "args, unknown = parser.parse_known_args()\n",
    "args.cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    print('\\nGPU is ON!')\n",
    "batch_size = 56 \n",
    "num_classes = 2\n",
    "n_channels = 3\n",
    "num_workers = 0\n",
    "img_width, img_height = 80, 80 \n",
    "datasetOC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posit_bags = ['01', '05', '53', '07', '37','55', '86','88','98','03','101','96']\n",
    "list_negat_bags = ['26', '61', '78', '59', '63','80', '68','71','75','65','73','70']\n",
    "\n",
    "name_class = ['negative', 'positive']\n",
    "root = '../fold1'\n",
    "dataset_name = f'PAPQMNIST_0012__{percent_key_ins:04d}_1'\n",
    "percent_key_ins = 10\n",
    "test_path_bags = os.path.join(root, dataset_name, 'test')\n",
    "num_test_bags=8\n",
    "gpu_number = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From MIL to SIL dataset\n",
    "data_folder = os.path.join(root, dataset_name)\n",
    "basePath = Path(data_folder)\n",
    "save_dir = create_save_dir(root, basePath.parts[-1]+'_SIL')\n",
    "if len(os.listdir(save_dir)) == 0:\n",
    "    for child in basePath.iterdir():\n",
    "        if child.is_dir() and (child.parts[-1]=='train' or child.parts[-1]=='valid' or child.parts[-1]=='test'):\n",
    "            set_folder = create_save_dir(save_dir, child.parts[-1])\n",
    "            for grandchild in child.iterdir():\n",
    "                if grandchild.is_dir():\n",
    "                    class_folder = create_save_dir(set_folder, grandchild.parts[-1])\n",
    "                    for ggrandchild in grandchild.iterdir():\n",
    "                        if ggrandchild.is_dir():\n",
    "                            files_names = list_files_in_folder(ggrandchild)\n",
    "                            for i in range(len(files_names)):\n",
    "                                src = os.path.join(ggrandchild, files_names[i])\n",
    "                                dst = os.path.join(class_folder, files_names[i])\n",
    "                                shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter inputs\n",
    "data_dir = os.path.join(root, basePath.parts[-1]+'_SIL')\n",
    "\n",
    "# mean, std of dataset\n",
    "mean_dataset = [0.5223, 0.6717, 0.7039] # example\n",
    "std_dataset = [0.1364, 0.1376, 0.1370] # example\n",
    "model_architecture = 'lenet' # resnet18, squeezenet, lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 'train'\n",
    "VAL = 'valid'\n",
    "TEST = 'test'\n",
    "\n",
    "data_transforms = transformations_dataset_oral_cancer3_focused(TRAIN, VAL, TEST, img_width, img_height, mean_dataset,\n",
    "                                                               std_dataset)\n",
    "dataset_sizes = {x: len(working_dataset(x, data_dir, data_transforms)) for x in [TRAIN, VAL, TEST]}\n",
    "for x in [TRAIN, VAL]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "print(\"Classes: \")\n",
    "class_names = working_dataset(TRAIN, data_dir, data_transforms).classes\n",
    "print(class_names)\n",
    "training_generator = load_dataset(working_dataset(TRAIN, data_dir, data_transforms), batch_size,\n",
    "                                  num_workers)\n",
    "train_iter = iter(training_generator)\n",
    "valid_generator = load_dataset(working_dataset(VAL, data_dir, data_transforms), batch_size, num_workers)\n",
    "test_generator = load_dataset(working_dataset(TEST, data_dir, data_transforms), batch_size, num_workers)\n",
    "\n",
    "files_train, files_test, files_valid, Labels = list_files_oral_cancer3_focused(data_dir, TRAIN, VAL, TEST,\n",
    "                                                                  negative_class='negative',\n",
    "                                                                  positive_class='positive')\n",
    "# Parameters for loader\n",
    "params = {'dim': (img_width, img_height),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'negative_class_name': 'negative',\n",
    "          'positive_class_name': 'positive',\n",
    "          'n_channels': n_channels,\n",
    "          'shuffle': True}\n",
    "partition = {'train': files_train, 'test': files_test, 'valid': files_valid}  # IDs\n",
    "training_generator = PAPQMNIST_SIL(partition['train'], Labels, data_transforms[TRAIN],\n",
    "                                                path=os.path.join(data_dir, TRAIN), **params)\n",
    "valid_generator = PAPQMNIST_SIL(partition['valid'], Labels, data_transforms[VAL],\n",
    "                                            path=os.path.join(data_dir, VAL), **params)\n",
    "test_generator = PAPQMNIST_SIL(partition['test'], Labels, data_transforms[TEST],\n",
    "                                            path=os.path.join(data_dir, TEST), **params)\n",
    "print('Init Model')\n",
    "\n",
    "if args.cuda:\n",
    "    if model_architecture=='resnet18':\n",
    "        model = ModelParallelResNet18(gpu_number) \n",
    "    elif model_architecture=='squeezenet':\n",
    "        model = ModelParallelSqueezeNet(gpu_number)\n",
    "    elif model_architecture=='lenet':\n",
    "        model = Lenet(gpu_number) \n",
    "window_length = 15 # valudation window of epochs for calculating moving average\n",
    "save_weights_dir = create_save_dir(os.path.join(data_dir), 'test_'+\n",
    "                                   '_train_epochs_'+str(args.epochs)+'_lr'+str(args.lr)+'_model_'+model_architecture+'SIL') \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999), weight_decay=args.reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(data_dir)\n",
    "all_train_loss = []; all_train_acc=[]; all_valid_loss=[]; all_valid_acc=[]; all_train_F1score=[];all_valid_F1score=[]\n",
    "all_valid_error=[]\n",
    "count_stable_epochs=[]; \n",
    "min_valid_loss = torch.tensor([float('inf')]).to('cuda:'+gpu_number) \n",
    "\n",
    "min_valid_error = np.inf; window_with_best_avg=np.inf\n",
    "num_epochs=args.epochs; lr=args.lr\n",
    "\n",
    "train_batches = len(training_generator)\n",
    "val_batches = len(valid_generator)\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"Training started\")\n",
    "    model.train()\n",
    "    train_loss = 0.; train_error = 0.\n",
    "    TN = 0; TP = 0; FN = 0; FP = 0; TN_train = 0; TP_train = 0; FN_train = 0; FP_train = 0\n",
    "    loss_train = 0;loss_valid = 0\n",
    "    acc_train = 0;acc_valid = 0\n",
    "    for i, data_all in enumerate(training_generator):\n",
    "        if i >= train_batches:\n",
    "            break\n",
    "        data, label = data_all\n",
    "        if args.cuda:\n",
    "            data, label = data.to('cuda:'+gpu_number), label.to('cuda:'+gpu_number) \n",
    "        data, label = Variable(data), Variable(label)\n",
    "\n",
    "        label = label.long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item()\n",
    "        acc_train += (torch.sum(preds == label.data)).item()\n",
    "        for bt_nr in range(len(preds)):\n",
    "            if label.data[bt_nr]==0:\n",
    "                if preds[bt_nr]==0:\n",
    "                    TN_train += 1\n",
    "                elif preds[bt_nr]==1:\n",
    "                    FP_train += 1\n",
    "                else:\n",
    "                    print(preds[bt_nr])\n",
    "            elif label.data[bt_nr]==1:\n",
    "                if preds[bt_nr]==1:\n",
    "                    TP_train += 1\n",
    "                elif preds[bt_nr]==0:\n",
    "                    FN_train += 1\n",
    "                else:\n",
    "                    print(preds[bt_nr])\n",
    "            else:\n",
    "                print(\"LABELS\",label.data[bt_nr])\n",
    "    # F1score:\n",
    "    Pr_train = TP_train/(TP_train+FP_train+1e-12)\n",
    "    Re_train = TP_train/(TP_train+FN_train+1e-12)\n",
    "    F1_score_train = 2*(Pr_train*Re_train)/(Pr_train+Re_train+1e-12)\n",
    "    train_loss = loss_train / len(training_generator.dataset)\n",
    "    train_acc = acc_train / len(training_generator.dataset)    \n",
    "    # Validation loss and error\n",
    "    valid_loss = 0.; valid_error = 0.\n",
    "    model.eval()\n",
    "    for i, data_all in enumerate(valid_generator):\n",
    "        if i >= val_batches:\n",
    "            break\n",
    "        data, label = data_all\n",
    "        if args.cuda:\n",
    "            data, label = data.to('cuda:'+gpu_number), label.to('cuda:'+gpu_number) \n",
    "        data, label = Variable(data), Variable(label) \n",
    "        label = label.long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss_valid += loss.item()\n",
    "        acc_valid += (torch.sum(preds == label.data)).item()\n",
    "        for bt_nr in range(len(preds)):\n",
    "            if label.data[bt_nr]==0:\n",
    "                if preds[bt_nr]==0:\n",
    "                    TN += 1\n",
    "                elif preds[bt_nr]==1:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    print(preds[bt_nr])\n",
    "            elif label.data[bt_nr]==1:\n",
    "                if preds[bt_nr]==1:\n",
    "                    TP += 1\n",
    "                elif preds[bt_nr]==0:\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    print(preds[bt_nr])\n",
    "            else:\n",
    "                print(\"LABELS\",label.data[bt_nr])\n",
    "        Conf_matrix = np.stack((TN,FP,FN,TP))\n",
    "    # F1score:\n",
    "    Pr = TP/(TP+FP+1e-12)\n",
    "    Re = TP/(TP+FN+1e-12)\n",
    "    F1_score = 2*(Pr*Re)/(Pr+Re+1e-12)\n",
    "    valid_loss = loss_valid / len(valid_generator.dataset)\n",
    "    valid_acc = acc_valid / len(valid_generator.dataset) \n",
    "    \n",
    "    # Save all losses for all epochs both valid and train\n",
    "    all_train_loss.append(train_loss) #(train_loss.cpu().data.numpy())\n",
    "    all_train_F1score.append(F1_score_train)\n",
    "    all_valid_loss.append(valid_loss)\n",
    "    all_valid_F1score.append(F1_score)\n",
    "    all_train_acc.append(train_acc)\n",
    "    all_valid_acc.append(valid_acc)\n",
    "    all_valid_error.append(1/(F1_score+10e-12))\n",
    "    \n",
    "    # Best validation F1score, within the best average window of F1score\n",
    "    name_epoch_model = os.path.join(path, 'saved_model_PAPQMNIST_'+path.parts[-1]+'_currentEpoch'+\\\n",
    "                                    str(epoch)+'_overallEpochs'+str(num_epochs)+'_lr'+str(lr)+'.pt')\n",
    "    torch.save(model.state_dict(), name_epoch_model)\n",
    "    if len(all_valid_error)>window_length-1:\n",
    "        avg_valid_error_window = np.mean(np.asarray(all_valid_error)[-window_length:])\n",
    "        \n",
    "        if window_with_best_avg > avg_valid_error_window:\n",
    "            idx_model_in_window_with_min_loss = np.argmin(np.asarray(all_valid_error)[-window_length:])\n",
    "            window_with_best_avg = avg_valid_error_window\n",
    "            name_best_inMovAv_val_error_model = os.path.join(path, 'saved_model_PAPQMNIST_'+path.parts[-1]+\n",
    "                                                            '_currentEpoch'+\n",
    "                                             str(epoch-window_length+idx_model_in_window_with_min_loss+1)+\n",
    "                                             '_overallEpochs'+str(num_epochs)+'_lr'+str(lr)+\n",
    "                                             '.pt')\n",
    "            print(\"Current best moving average model, epoch: \", str(epoch-window_length+idx_model_in_window_with_min_loss+1))\n",
    "            epoch_best_movingAvg = epoch-window_length+idx_model_in_window_with_min_loss+1\n",
    "    #to delete models that are outside current window except the best_window_model_name\n",
    "    for ep in range(0, epoch-window_length):\n",
    "        model_nametmp = os.path.join(path, 'saved_model_PAPQMNIST_'+path.parts[-1]+'_currentEpoch'+\n",
    "                                     str(ep+1)+'_overallEpochs'+str(num_epochs)+'_lr'+str(lr)+\n",
    "                                     '.pt')\n",
    "        if model_nametmp != name_best_inMovAv_val_error_model and os.path.isfile(model_nametmp):\n",
    "            os.remove(model_nametmp)\n",
    "    \n",
    "    print('Epoch: {}, Loss: {:.4f}, Train F1: {:.4f}'.format(epoch, train_loss, F1_score_train))\n",
    "    print('Epoch: {}, Loss: {:.4f}, Valid F1: {:.4f}'.format(epoch, valid_loss, F1_score))\n",
    "\n",
    "    \n",
    "new_name_best_inMovAv_val_error_model = os.path.join(save_weights_dir, 'saved_model_best_movingAvg_PAPQMNIST_'+\\\n",
    "                                                     path.parts[-1]+'epochSaved_'+str(epoch_best_movingAvg)+\n",
    "                                                     '_overallEpochs'+str(num_epochs)+'_lr'+str(lr)+\n",
    "                                                     '.pt')\n",
    "shutil.move(name_best_inMovAv_val_error_model, new_name_best_inMovAv_val_error_model)\n",
    "    \n",
    "    \n",
    "for ep in range(1,num_epochs+1):\n",
    "    model_nametmp = os.path.join(path, 'saved_model_PAPQMNIST_'+path.parts[-1]+'_currentEpoch'+str(ep)+\n",
    "                                 '_overallEpochs'+str(num_epochs)+'_lr'+str(lr)+'.pt')\n",
    "    if os.path.isfile(model_nametmp):\n",
    "        os.remove(model_nametmp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(new_name_best_inMovAv_val_error_model))\n",
    "model_path = Path(new_name_best_inMovAv_val_error_model)\n",
    "model.eval()\n",
    "device = 'cuda:'+gpu_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_extr = [False, True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate number of instances classified as positive/negative in patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flag in valid_extr:\n",
    "    postproc(flag, data_dir, data_transforms, name_class, save_weights_dir, model_path, device, TEST, VAL, model, test_path_bags, list_posit_bags, list_negat_bags)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 folds to be run and average threshold separating positive and negative bags for validation sets to be computed, \n",
    "# use this threshold to define if a test bag is classified as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 36 top score for each patient with malignancy\n",
    "cl_ind = 1\n",
    "output_dir = os.path.join(save_weights_dir, 'test', name_class[cl_ind], name_class[cl_ind] + '_'+ model_path.parts[-1])\n",
    "top36dir = create_save_dir(os.path.join(save_weights_dir, 'test', name_class[cl_ind]), 'top36')\n",
    "score_names = list_files_in_folder(os.path.join(output_dir))\n",
    "\n",
    "list_bags = list_posit_bags\n",
    "for b in range(len(list_bags)):\n",
    "    bag_folder = os.path.join(test_path_bags, name_class[cl_ind], list_bags[b])\n",
    "    if os.path.exists(os.path.join(bag_folder)):\n",
    "        save_36 = create_save_dir(top36dir, list_bags[b])\n",
    "        bag_folder_names = list_files_in_folder(bag_folder)  \n",
    "        \n",
    "        bag_pos_scores=[]; bag_names=[]\n",
    "        for i in range(len(score_names)):\n",
    "            if score_names[i][:-4] in bag_folder_names:\n",
    "                score_temp = np.load(os.path.join(output_dir, score_names[i]))\n",
    "                bag_pos_scores.append(score_temp)\n",
    "                bag_names.append(score_names[i])\n",
    "        bag_pos_scores_array = np.asarray(bag_pos_scores)\n",
    "        idxs = np.flip(np.argsort(bag_pos_scores_array)) \n",
    "        top36 = []\n",
    "        for i in range(36):\n",
    "            top36.append(bag_names[idxs[i]])\n",
    "            src=os.path.join(data_dir, 'test', name_class[cl_ind], bag_names[idxs[i]][:-4])\n",
    "            dst=os.path.join(save_36, bag_names[idxs[i]][:-4])\n",
    "            shutil.copy(src, dst)\n",
    "        np.save(os.path.join(save_36,'top36.npy'),np.asarray(top36))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute AUC at the instance level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bag_labels_negat = {'26':0,'61':0 ,'73':0,'70':0} #example\n",
    "pred_bag_labels_posit = {'07':1,'37':1,'101':1,'96':1} #example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datasetOC==False:\n",
    "    true_bag_label=[0,1]\n",
    "    count_TP=0;count_TN=0;count_FP=0;count_FN=0;\n",
    "    all_true_labels=[]; all_pred_labels=[]\n",
    "    AUC_all_bags=[]; AUC_positive_bags=[]; sens_all_bags=[]; spec_all_bags=[]\n",
    "    for cl_ind in range(len(name_class)):\n",
    "        if cl_ind==0:\n",
    "            list_bags=list_negat_bags\n",
    "            pred_bag_dict = pred_bag_labels_negat\n",
    "        else:\n",
    "            list_bags=list_posit_bags\n",
    "            pred_bag_dict = pred_bag_labels_posit\n",
    "        dirname = Path(os.path.join(save_weights_dir, 'test', name_class[cl_ind]))\n",
    "        listing = [f for f in dirname.iterdir() if f.is_dir()]\n",
    "        output_dir = str(listing[0])\n",
    "        print(output_dir)\n",
    "        score_names = list_files_in_folder(os.path.join(output_dir))\n",
    "\n",
    "        for b in range(len(list_bags)):\n",
    "            all_images_in_bag_score=[]; all_names_in_bag=[]\n",
    "            all_pred_sample_labels=[]\n",
    "            bag_folder = os.path.join(test_path_bags, name_class[cl_ind], list_bags[b])\n",
    "            if os.path.exists(os.path.join(bag_folder)):\n",
    "                print(list_bags[b])\n",
    "                pred_label_bag = pred_bag_dict[list_bags[b]]\n",
    "                print(pred_label_bag)\n",
    "                bag_folder_names = list_files_in_folder(bag_folder)\n",
    "                for i in range(len(score_names)):\n",
    "                    score_temp = np.load(os.path.join(output_dir, score_names[i]))\n",
    "                    if score_names[i][:-4] in bag_folder_names:\n",
    "                        all_images_in_bag_score.append(score_temp)\n",
    "                        all_names_in_bag.append(score_names[i])\n",
    "\n",
    "                scores_in_bag = np.asarray(all_images_in_bag_score)\n",
    "                imgs_names_in_bag = np.asarray(all_names_in_bag)\n",
    "                ### Instance level\n",
    "                all_TPR=[]; all_FPR=[]\n",
    "                threshold_range = np.arange(0,1+0.01,0.01)\n",
    "                for th in range(len(threshold_range)):\n",
    "                    count_TP_ins=0;count_TN_ins=0;count_FP_ins=0;count_FN_ins=0\n",
    "                    Threshold = threshold_range[th]\n",
    "                    for k in range(len(scores_in_bag)): #for k in range(len(arr)):\n",
    "                        if scores_in_bag[k]>=Threshold and pred_label_bag==1 and imgs_names_in_bag[k][0]==str('4'):\n",
    "                            count_TP_ins+=1\n",
    "                        elif scores_in_bag[k]>=Threshold and pred_label_bag==1 and imgs_names_in_bag[k][0]!=str('4'):\n",
    "                            count_FP_ins+=1          \n",
    "                        elif (scores_in_bag[k]>=Threshold and pred_label_bag==0 and imgs_names_in_bag[k][0]!=str('4')) or \\\n",
    "                    (scores_in_bag[k]<Threshold and imgs_names_in_bag[k][0]==str('4')):\n",
    "                            count_TN_ins+=1      \n",
    "                        elif (scores_in_bag[k]>=Threshold and pred_label_bag==0 and imgs_names_in_bag[k][0]==str('4')) or \\\n",
    "                    (scores_in_bag[k]<Threshold and imgs_names_in_bag[k][0]==str('4')):\n",
    "                            count_FN_ins+=1              \n",
    "\n",
    "                    # TPR, FPR for a certain threshold\n",
    "                    TPR = count_TP_ins/(count_TP_ins+count_FN_ins+1e-12)\n",
    "                    FPR = count_FP_ins/(count_FP_ins+count_TN_ins+1e-12)\n",
    "                    all_TPR.append(np.around(TPR, decimals=4)); all_FPR.append(np.around(FPR, decimals=4))\n",
    "\n",
    "                AUC_bag = sklearn.metrics.auc(np.asarray(all_FPR), np.asarray(all_TPR))\n",
    "                print(AUC_bag)\n",
    "                AUC_all_bags.append(np.around(AUC_bag, decimals=5))\n",
    "\n",
    "                if true_bag_label[cl_ind]==1: #for positive bags\n",
    "                    AUC_positive_bags.append(np.around(AUC_bag, decimals=5))              \n",
    "    print('AUC for positive bags, instance level:', \n",
    "              np.around(np.sum(np.asarray(AUC_positive_bags))/(num_test_bags/2), decimals=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
